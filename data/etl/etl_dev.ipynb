{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Development\n",
    "### phase 0\n",
    "| Task                                  | Status      | Comments  |\n",
    "|---------------------------------------|-------------|-----------|\n",
    "| Manually clone Azure repo             | Complete    | use single branch clone <br>* still receiving 600k+ objects (31.57GiB) <br>* full clone was 7.9 million      |\n",
    "| Crawl through repo & get all md files | In Progress | None      |\n",
    "| Prepare md for indexing               | In progress | None      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global vars\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = \"/Users/alex/Desktop/code_projects/commuter-copilot/\"\n",
    "RAW_DATA_SOURCE_PATH = os.path.join(\n",
    "    PROJECT_ROOT, \"local_files\", \"data\", \"raw\", \"azure-docs\"\n",
    ")\n",
    "STAGED_DATA_SOURCE_PATH = os.path.join(\n",
    "    PROJECT_ROOT, \"local_files\", \"data\", \"staging\", \"azure-docs-staging\"\n",
    ")\n",
    "\n",
    "# Ensure the directories exist\n",
    "os.makedirs(RAW_DATA_SOURCE_PATH, exist_ok=True)\n",
    "os.makedirs(STAGED_DATA_SOURCE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually update & clone azure repo to local_files/ in terminal:\n",
    "# currently broken\n",
    "# !bash -c \"$PROJECT_ROOT/data/etl/run_etl_azure_docs_raw.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all md files in the raw data source path\n",
    "def find_md_files(path):\n",
    "    md_files = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".md\"):\n",
    "                md_files.append(os.path.join(root, file))\n",
    "    return md_files\n",
    "\n",
    "\n",
    "all_md_files = find_md_files(RAW_DATA_SOURCE_PATH)\n",
    "all_md_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from frontmatter import Frontmatter\n",
    "import os\n",
    "\n",
    "\n",
    "def process_markdown_file(file_path: str) -> dict:\n",
    "    \"\"\"Process a markdown file into an indexable document.\"\"\"\n",
    "    try:\n",
    "        post = Frontmatter.read_file(file_path)\n",
    "        doc_id = str(uuid.uuid4())\n",
    "        # Attempt to extract title: frontmatter 'title' key or first markdown header\n",
    "        title = post[\"attributes\"][\"title\"] or extract_title(post[\"body\"])\n",
    "\n",
    "        return {\n",
    "            \"id\": doc_id,\n",
    "            \"filename\": os.path.basename(file_path),\n",
    "            \"path\": file_path,\n",
    "            \"title\": title,\n",
    "            \"content\": post[\"body\"],\n",
    "            \"metadata\": {k: v for k, v in post[\"attributes\"].items() if k != \"title\"},\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_title(content: str) -> str:\n",
    "    \"\"\"A simple heuristic: use the first line that starts with a '#'.\"\"\"\n",
    "    for line in content.splitlines():\n",
    "        if line.startswith(\"#\"):\n",
    "            return line.lstrip(\"# \").strip()\n",
    "    return \"Untitled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_md = \"/Users/alex/Desktop/code_projects/commuter-copilot/local_files/data/raw/azure-docs/articles/container-apps/alerts.md\"\n",
    "single_md2 = all_md_files[0]\n",
    "\n",
    "post = process_markdown_file(single_md)\n",
    "# print(post[\"metadata\"])\n",
    "# print(post.keys())\n",
    "post2 = process_markdown_file(single_md2)\n",
    "print(post2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_sample = all_md_files[4:8]\n",
    "processed_docs = []\n",
    "for file_path in all_md_files:\n",
    "    try:\n",
    "        processed_doc = process_markdown_file(file_path)\n",
    "        if processed_doc is None:\n",
    "            print(f\"Skipping {file_path} due to processing error.\")\n",
    "            continue\n",
    "        processed_docs.append(processed_doc)\n",
    "        # print(f\"Processed {file_path} successfully.\\n\\n{processed_doc['title']}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ingestion_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
